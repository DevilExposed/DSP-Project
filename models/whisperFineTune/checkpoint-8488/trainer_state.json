{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.993285428201202,
  "eval_steps": 1000,
  "global_step": 8488,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04711980209683119,
      "grad_norm": 66.955810546875,
      "learning_rate": 9.200000000000001e-07,
      "loss": 6.5545,
      "step": 50
    },
    {
      "epoch": 0.09423960419366238,
      "grad_norm": 24.88780403137207,
      "learning_rate": 1.9200000000000003e-06,
      "loss": 3.8421,
      "step": 100
    },
    {
      "epoch": 0.14135940629049357,
      "grad_norm": 15.878350257873535,
      "learning_rate": 2.92e-06,
      "loss": 1.9552,
      "step": 150
    },
    {
      "epoch": 0.18847920838732476,
      "grad_norm": 9.513854026794434,
      "learning_rate": 3.920000000000001e-06,
      "loss": 1.1326,
      "step": 200
    },
    {
      "epoch": 0.23559901048415596,
      "grad_norm": 9.742460250854492,
      "learning_rate": 4.92e-06,
      "loss": 0.9897,
      "step": 250
    },
    {
      "epoch": 0.28271881258098713,
      "grad_norm": 9.320159912109375,
      "learning_rate": 5.92e-06,
      "loss": 0.9041,
      "step": 300
    },
    {
      "epoch": 0.32983861467781833,
      "grad_norm": 8.372127532958984,
      "learning_rate": 6.92e-06,
      "loss": 0.8913,
      "step": 350
    },
    {
      "epoch": 0.37695841677464953,
      "grad_norm": 10.080796241760254,
      "learning_rate": 7.92e-06,
      "loss": 0.8339,
      "step": 400
    },
    {
      "epoch": 0.4240782188714807,
      "grad_norm": 8.895142555236816,
      "learning_rate": 8.920000000000001e-06,
      "loss": 0.7947,
      "step": 450
    },
    {
      "epoch": 0.4711980209683119,
      "grad_norm": 8.465394020080566,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.7704,
      "step": 500
    },
    {
      "epoch": 0.5183178230651432,
      "grad_norm": 8.032370567321777,
      "learning_rate": 9.999181784957013e-06,
      "loss": 0.7884,
      "step": 550
    },
    {
      "epoch": 0.5654376251619743,
      "grad_norm": 10.413834571838379,
      "learning_rate": 9.996436682533159e-06,
      "loss": 0.7598,
      "step": 600
    },
    {
      "epoch": 0.6125574272588055,
      "grad_norm": 7.7213873863220215,
      "learning_rate": 9.991759567150896e-06,
      "loss": 0.7594,
      "step": 650
    },
    {
      "epoch": 0.6596772293556367,
      "grad_norm": 8.089559555053711,
      "learning_rate": 9.985152247348607e-06,
      "loss": 0.7532,
      "step": 700
    },
    {
      "epoch": 0.7067970314524679,
      "grad_norm": 8.355067253112793,
      "learning_rate": 9.97661727803258e-06,
      "loss": 0.7659,
      "step": 750
    },
    {
      "epoch": 0.7539168335492991,
      "grad_norm": 8.221397399902344,
      "learning_rate": 9.966157959489068e-06,
      "loss": 0.716,
      "step": 800
    },
    {
      "epoch": 0.8010366356461303,
      "grad_norm": 7.689911365509033,
      "learning_rate": 9.953778336108158e-06,
      "loss": 0.6999,
      "step": 850
    },
    {
      "epoch": 0.8481564377429615,
      "grad_norm": 8.84598445892334,
      "learning_rate": 9.939483194819872e-06,
      "loss": 0.7179,
      "step": 900
    },
    {
      "epoch": 0.8952762398397927,
      "grad_norm": 8.063246726989746,
      "learning_rate": 9.92327806324319e-06,
      "loss": 0.7066,
      "step": 950
    },
    {
      "epoch": 0.9423960419366239,
      "grad_norm": 7.245024681091309,
      "learning_rate": 9.90516920754862e-06,
      "loss": 0.71,
      "step": 1000
    },
    {
      "epoch": 0.989515844033455,
      "grad_norm": 7.663282871246338,
      "learning_rate": 9.885163630035219e-06,
      "loss": 0.7052,
      "step": 1050
    },
    {
      "epoch": 1.0358110495935917,
      "grad_norm": 8.006731986999512,
      "learning_rate": 9.863269066422951e-06,
      "loss": 0.6116,
      "step": 1100
    },
    {
      "epoch": 1.0829308516904228,
      "grad_norm": 7.279378414154053,
      "learning_rate": 9.839493982861454e-06,
      "loss": 0.5893,
      "step": 1150
    },
    {
      "epoch": 1.1300506537872541,
      "grad_norm": 8.397686958312988,
      "learning_rate": 9.81384757265637e-06,
      "loss": 0.5879,
      "step": 1200
    },
    {
      "epoch": 1.1771704558840852,
      "grad_norm": 8.205098152160645,
      "learning_rate": 9.786339752714482e-06,
      "loss": 0.607,
      "step": 1250
    },
    {
      "epoch": 1.2242902579809165,
      "grad_norm": 9.108696937561035,
      "learning_rate": 9.756981159709082e-06,
      "loss": 0.5985,
      "step": 1300
    },
    {
      "epoch": 1.2714100600777476,
      "grad_norm": 6.696335315704346,
      "learning_rate": 9.72578314596698e-06,
      "loss": 0.6,
      "step": 1350
    },
    {
      "epoch": 1.318529862174579,
      "grad_norm": 6.801159381866455,
      "learning_rate": 9.692757775078822e-06,
      "loss": 0.5974,
      "step": 1400
    },
    {
      "epoch": 1.36564966427141,
      "grad_norm": 7.884622097015381,
      "learning_rate": 9.657917817234361e-06,
      "loss": 0.5868,
      "step": 1450
    },
    {
      "epoch": 1.4127694663682413,
      "grad_norm": 7.772242069244385,
      "learning_rate": 9.621276744284496e-06,
      "loss": 0.5774,
      "step": 1500
    },
    {
      "epoch": 1.4598892684650724,
      "grad_norm": 7.203071117401123,
      "learning_rate": 9.58284872453201e-06,
      "loss": 0.5784,
      "step": 1550
    },
    {
      "epoch": 1.5070090705619035,
      "grad_norm": 7.124021053314209,
      "learning_rate": 9.542648617252994e-06,
      "loss": 0.5915,
      "step": 1600
    },
    {
      "epoch": 1.5541288726587348,
      "grad_norm": 10.667391777038574,
      "learning_rate": 9.500691966951085e-06,
      "loss": 0.5766,
      "step": 1650
    },
    {
      "epoch": 1.601248674755566,
      "grad_norm": 7.028783798217773,
      "learning_rate": 9.45699499734675e-06,
      "loss": 0.5923,
      "step": 1700
    },
    {
      "epoch": 1.6483684768523972,
      "grad_norm": 6.494816303253174,
      "learning_rate": 9.411574605103931e-06,
      "loss": 0.5533,
      "step": 1750
    },
    {
      "epoch": 1.6954882789492283,
      "grad_norm": 7.346402168273926,
      "learning_rate": 9.364448353296464e-06,
      "loss": 0.573,
      "step": 1800
    },
    {
      "epoch": 1.7426080810460596,
      "grad_norm": 6.604307651519775,
      "learning_rate": 9.315634464616834e-06,
      "loss": 0.5843,
      "step": 1850
    },
    {
      "epoch": 1.7897278831428909,
      "grad_norm": 6.279153823852539,
      "learning_rate": 9.265151814329849e-06,
      "loss": 0.5557,
      "step": 1900
    },
    {
      "epoch": 1.836847685239722,
      "grad_norm": 6.471811771392822,
      "learning_rate": 9.213019922973988e-06,
      "loss": 0.5737,
      "step": 1950
    },
    {
      "epoch": 1.883967487336553,
      "grad_norm": 7.350223064422607,
      "learning_rate": 9.159258948813242e-06,
      "loss": 0.5612,
      "step": 2000
    },
    {
      "epoch": 1.9310872894333844,
      "grad_norm": 6.507946014404297,
      "learning_rate": 9.103889680042342e-06,
      "loss": 0.5422,
      "step": 2050
    },
    {
      "epoch": 1.9782070915302157,
      "grad_norm": 8.30107307434082,
      "learning_rate": 9.046933526748431e-06,
      "loss": 0.5797,
      "step": 2100
    },
    {
      "epoch": 2.0245022970903523,
      "grad_norm": 7.383164405822754,
      "learning_rate": 8.988412512632239e-06,
      "loss": 0.5154,
      "step": 2150
    },
    {
      "epoch": 2.0716220991871834,
      "grad_norm": 6.4141645431518555,
      "learning_rate": 8.92834926649201e-06,
      "loss": 0.4682,
      "step": 2200
    },
    {
      "epoch": 2.1187419012840145,
      "grad_norm": 5.302613258361816,
      "learning_rate": 8.866767013473427e-06,
      "loss": 0.4717,
      "step": 2250
    },
    {
      "epoch": 2.1658617033808456,
      "grad_norm": 7.250715732574463,
      "learning_rate": 8.803689566088971e-06,
      "loss": 0.4664,
      "step": 2300
    },
    {
      "epoch": 2.212981505477677,
      "grad_norm": 6.819553375244141,
      "learning_rate": 8.739141315010125e-06,
      "loss": 0.4647,
      "step": 2350
    },
    {
      "epoch": 2.2601013075745082,
      "grad_norm": 6.607829570770264,
      "learning_rate": 8.673147219636048e-06,
      "loss": 0.4711,
      "step": 2400
    },
    {
      "epoch": 2.3072211096713393,
      "grad_norm": 6.598039150238037,
      "learning_rate": 8.605732798442317e-06,
      "loss": 0.4772,
      "step": 2450
    },
    {
      "epoch": 2.3543409117681704,
      "grad_norm": 5.843273639678955,
      "learning_rate": 8.536924119113482e-06,
      "loss": 0.471,
      "step": 2500
    },
    {
      "epoch": 2.401460713865002,
      "grad_norm": 5.251497745513916,
      "learning_rate": 8.46674778846327e-06,
      "loss": 0.4531,
      "step": 2550
    },
    {
      "epoch": 2.448580515961833,
      "grad_norm": 6.150594711303711,
      "learning_rate": 8.39523094214631e-06,
      "loss": 0.4791,
      "step": 2600
    },
    {
      "epoch": 2.495700318058664,
      "grad_norm": 6.827668190002441,
      "learning_rate": 8.32240123416537e-06,
      "loss": 0.4709,
      "step": 2650
    },
    {
      "epoch": 2.542820120155495,
      "grad_norm": 6.932879447937012,
      "learning_rate": 8.248286826178144e-06,
      "loss": 0.4768,
      "step": 2700
    },
    {
      "epoch": 2.5899399222523263,
      "grad_norm": 5.766443252563477,
      "learning_rate": 8.172916376607779e-06,
      "loss": 0.4599,
      "step": 2750
    },
    {
      "epoch": 2.637059724349158,
      "grad_norm": 6.1676130294799805,
      "learning_rate": 8.096319029561258e-06,
      "loss": 0.4738,
      "step": 2800
    },
    {
      "epoch": 2.684179526445989,
      "grad_norm": 6.621783256530762,
      "learning_rate": 8.018524403560039e-06,
      "loss": 0.4517,
      "step": 2850
    },
    {
      "epoch": 2.73129932854282,
      "grad_norm": 6.3566765785217285,
      "learning_rate": 7.939562580087204e-06,
      "loss": 0.465,
      "step": 2900
    },
    {
      "epoch": 2.7784191306396515,
      "grad_norm": 6.282227039337158,
      "learning_rate": 7.859464091955606e-06,
      "loss": 0.4537,
      "step": 2950
    },
    {
      "epoch": 2.8255389327364826,
      "grad_norm": 6.161502361297607,
      "learning_rate": 7.778259911501502e-06,
      "loss": 0.4723,
      "step": 3000
    },
    {
      "epoch": 2.8726587348333137,
      "grad_norm": 6.088625907897949,
      "learning_rate": 7.695981438608226e-06,
      "loss": 0.4672,
      "step": 3050
    },
    {
      "epoch": 2.9197785369301448,
      "grad_norm": 6.842179298400879,
      "learning_rate": 7.612660488564537e-06,
      "loss": 0.4653,
      "step": 3100
    },
    {
      "epoch": 2.966898339026976,
      "grad_norm": 7.117626667022705,
      "learning_rate": 7.528329279762348e-06,
      "loss": 0.4587,
      "step": 3150
    },
    {
      "epoch": 3.0131935445871125,
      "grad_norm": 6.023928165435791,
      "learning_rate": 7.443020421238567e-06,
      "loss": 0.4243,
      "step": 3200
    },
    {
      "epoch": 3.060313346683944,
      "grad_norm": 5.910435199737549,
      "learning_rate": 7.356766900065904e-06,
      "loss": 0.3865,
      "step": 3250
    },
    {
      "epoch": 3.107433148780775,
      "grad_norm": 6.3628621101379395,
      "learning_rate": 7.269602068597488e-06,
      "loss": 0.4035,
      "step": 3300
    },
    {
      "epoch": 3.1545529508776062,
      "grad_norm": 4.80826473236084,
      "learning_rate": 7.181559631570234e-06,
      "loss": 0.3816,
      "step": 3350
    },
    {
      "epoch": 3.2016727529744373,
      "grad_norm": 6.703799247741699,
      "learning_rate": 7.09267363307197e-06,
      "loss": 0.3738,
      "step": 3400
    },
    {
      "epoch": 3.248792555071269,
      "grad_norm": 5.956848621368408,
      "learning_rate": 7.00297844337732e-06,
      "loss": 0.3762,
      "step": 3450
    },
    {
      "epoch": 3.2959123571681,
      "grad_norm": 5.367738246917725,
      "learning_rate": 6.912508745657469e-06,
      "loss": 0.3868,
      "step": 3500
    },
    {
      "epoch": 3.343032159264931,
      "grad_norm": 6.522700309753418,
      "learning_rate": 6.8212995225689495e-06,
      "loss": 0.3875,
      "step": 3550
    },
    {
      "epoch": 3.390151961361762,
      "grad_norm": 6.3910746574401855,
      "learning_rate": 6.729386042726602e-06,
      "loss": 0.3752,
      "step": 3600
    },
    {
      "epoch": 3.4372717634585936,
      "grad_norm": 6.879223823547363,
      "learning_rate": 6.636803847065977e-06,
      "loss": 0.3876,
      "step": 3650
    },
    {
      "epoch": 3.4843915655554247,
      "grad_norm": 6.457106113433838,
      "learning_rate": 6.543588735100425e-06,
      "loss": 0.3722,
      "step": 3700
    },
    {
      "epoch": 3.531511367652256,
      "grad_norm": 6.206078052520752,
      "learning_rate": 6.449776751078215e-06,
      "loss": 0.4031,
      "step": 3750
    },
    {
      "epoch": 3.578631169749087,
      "grad_norm": 7.6470160484313965,
      "learning_rate": 6.355404170045003e-06,
      "loss": 0.3816,
      "step": 3800
    },
    {
      "epoch": 3.6257509718459184,
      "grad_norm": 6.180011749267578,
      "learning_rate": 6.260507483817071e-06,
      "loss": 0.3873,
      "step": 3850
    },
    {
      "epoch": 3.6728707739427495,
      "grad_norm": 6.7605109214782715,
      "learning_rate": 6.165123386870735e-06,
      "loss": 0.3789,
      "step": 3900
    },
    {
      "epoch": 3.7199905760395806,
      "grad_norm": 7.720603942871094,
      "learning_rate": 6.069288762153384e-06,
      "loss": 0.3822,
      "step": 3950
    },
    {
      "epoch": 3.7671103781364117,
      "grad_norm": 6.565162181854248,
      "learning_rate": 5.973040666821671e-06,
      "loss": 0.3878,
      "step": 4000
    },
    {
      "epoch": 3.814230180233243,
      "grad_norm": 6.523111820220947,
      "learning_rate": 5.876416317912297e-06,
      "loss": 0.3885,
      "step": 4050
    },
    {
      "epoch": 3.8613499823300743,
      "grad_norm": 5.85706090927124,
      "learning_rate": 5.779453077951007e-06,
      "loss": 0.3913,
      "step": 4100
    },
    {
      "epoch": 3.9084697844269054,
      "grad_norm": 5.975706577301025,
      "learning_rate": 5.6821884405053195e-06,
      "loss": 0.3934,
      "step": 4150
    },
    {
      "epoch": 3.9555895865237365,
      "grad_norm": 8.306146621704102,
      "learning_rate": 5.584660015686575e-06,
      "loss": 0.3898,
      "step": 4200
    },
    {
      "epoch": 4.001884792083874,
      "grad_norm": 5.1916704177856445,
      "learning_rate": 5.488862576788542e-06,
      "loss": 0.3843,
      "step": 4250
    },
    {
      "epoch": 4.049004594180705,
      "grad_norm": 5.08062219619751,
      "learning_rate": 5.390923195562712e-06,
      "loss": 0.3312,
      "step": 4300
    },
    {
      "epoch": 4.096124396277536,
      "grad_norm": 5.4623236656188965,
      "learning_rate": 5.292832652873711e-06,
      "loss": 0.3235,
      "step": 4350
    },
    {
      "epoch": 4.143244198374367,
      "grad_norm": 6.028131484985352,
      "learning_rate": 5.194628878192401e-06,
      "loss": 0.335,
      "step": 4400
    },
    {
      "epoch": 4.190364000471198,
      "grad_norm": 4.7774810791015625,
      "learning_rate": 5.09634984477399e-06,
      "loss": 0.3241,
      "step": 4450
    },
    {
      "epoch": 4.237483802568029,
      "grad_norm": 4.950177192687988,
      "learning_rate": 4.9980335549745874e-06,
      "loss": 0.3191,
      "step": 4500
    },
    {
      "epoch": 4.28460360466486,
      "grad_norm": 5.466645240783691,
      "learning_rate": 4.899718025556533e-06,
      "loss": 0.3224,
      "step": 4550
    },
    {
      "epoch": 4.331723406761691,
      "grad_norm": 6.009377956390381,
      "learning_rate": 4.80144127298815e-06,
      "loss": 0.3335,
      "step": 4600
    },
    {
      "epoch": 4.378843208858523,
      "grad_norm": 6.586225509643555,
      "learning_rate": 4.703241298743593e-06,
      "loss": 0.3322,
      "step": 4650
    },
    {
      "epoch": 4.425963010955354,
      "grad_norm": 6.445806503295898,
      "learning_rate": 4.605156074608519e-06,
      "loss": 0.3399,
      "step": 4700
    },
    {
      "epoch": 4.473082813052185,
      "grad_norm": 6.218982696533203,
      "learning_rate": 4.507223527997223e-06,
      "loss": 0.3407,
      "step": 4750
    },
    {
      "epoch": 4.5202026151490164,
      "grad_norm": 5.631044387817383,
      "learning_rate": 4.409481527286937e-06,
      "loss": 0.3187,
      "step": 4800
    },
    {
      "epoch": 4.5673224172458475,
      "grad_norm": 5.8808913230896,
      "learning_rate": 4.311967867174951e-06,
      "loss": 0.3343,
      "step": 4850
    },
    {
      "epoch": 4.614442219342679,
      "grad_norm": 5.304721832275391,
      "learning_rate": 4.214720254064235e-06,
      "loss": 0.3386,
      "step": 4900
    },
    {
      "epoch": 4.66156202143951,
      "grad_norm": 6.91631555557251,
      "learning_rate": 4.117776291483191e-06,
      "loss": 0.3252,
      "step": 4950
    },
    {
      "epoch": 4.708681823536341,
      "grad_norm": 5.3585591316223145,
      "learning_rate": 4.021173465545191e-06,
      "loss": 0.3241,
      "step": 5000
    },
    {
      "epoch": 4.755801625633172,
      "grad_norm": 5.690662860870361,
      "learning_rate": 3.924949130453522e-06,
      "loss": 0.3412,
      "step": 5050
    },
    {
      "epoch": 4.802921427730004,
      "grad_norm": 5.629427433013916,
      "learning_rate": 3.82914049405732e-06,
      "loss": 0.333,
      "step": 5100
    },
    {
      "epoch": 4.850041229826835,
      "grad_norm": 5.7356109619140625,
      "learning_rate": 3.7337846034641134e-06,
      "loss": 0.3387,
      "step": 5150
    },
    {
      "epoch": 4.897161031923666,
      "grad_norm": 4.812760353088379,
      "learning_rate": 3.6389183307145204e-06,
      "loss": 0.3185,
      "step": 5200
    },
    {
      "epoch": 4.944280834020497,
      "grad_norm": 5.6430983543396,
      "learning_rate": 3.5445783585246242e-06,
      "loss": 0.3379,
      "step": 5250
    },
    {
      "epoch": 4.991400636117328,
      "grad_norm": 5.246792793273926,
      "learning_rate": 3.45080116610158e-06,
      "loss": 0.3389,
      "step": 5300
    },
    {
      "epoch": 5.037695841677465,
      "grad_norm": 5.5739946365356445,
      "learning_rate": 3.357623015037891e-06,
      "loss": 0.2847,
      "step": 5350
    },
    {
      "epoch": 5.084815643774296,
      "grad_norm": 4.850769996643066,
      "learning_rate": 3.265079935289852e-06,
      "loss": 0.3036,
      "step": 5400
    },
    {
      "epoch": 5.131935445871127,
      "grad_norm": 4.816689491271973,
      "learning_rate": 3.173207711245547e-06,
      "loss": 0.2927,
      "step": 5450
    },
    {
      "epoch": 5.179055247967958,
      "grad_norm": 5.0126633644104,
      "learning_rate": 3.082041867887809e-06,
      "loss": 0.293,
      "step": 5500
    },
    {
      "epoch": 5.22617505006479,
      "grad_norm": 4.872500896453857,
      "learning_rate": 2.9916176570574833e-06,
      "loss": 0.2899,
      "step": 5550
    },
    {
      "epoch": 5.273294852161621,
      "grad_norm": 4.708423614501953,
      "learning_rate": 2.9019700438223146e-06,
      "loss": 0.2951,
      "step": 5600
    },
    {
      "epoch": 5.320414654258452,
      "grad_norm": 5.201178550720215,
      "learning_rate": 2.8131336929567123e-06,
      "loss": 0.3025,
      "step": 5650
    },
    {
      "epoch": 5.367534456355283,
      "grad_norm": 5.161935329437256,
      "learning_rate": 2.7251429555376457e-06,
      "loss": 0.2962,
      "step": 5700
    },
    {
      "epoch": 5.4146542584521145,
      "grad_norm": 5.183803081512451,
      "learning_rate": 2.638031855661829e-06,
      "loss": 0.2959,
      "step": 5750
    },
    {
      "epoch": 5.4617740605489455,
      "grad_norm": 6.246938228607178,
      "learning_rate": 2.551834077289348e-06,
      "loss": 0.2842,
      "step": 5800
    },
    {
      "epoch": 5.508893862645777,
      "grad_norm": 5.7099432945251465,
      "learning_rate": 2.4665829512188076e-06,
      "loss": 0.2956,
      "step": 5850
    },
    {
      "epoch": 5.556013664742608,
      "grad_norm": 4.756582260131836,
      "learning_rate": 2.3823114421990344e-06,
      "loss": 0.2893,
      "step": 5900
    },
    {
      "epoch": 5.60313346683944,
      "grad_norm": 5.651871681213379,
      "learning_rate": 2.2990521361823397e-06,
      "loss": 0.3011,
      "step": 5950
    },
    {
      "epoch": 5.650253268936271,
      "grad_norm": 6.980545520782471,
      "learning_rate": 2.216837227724234e-06,
      "loss": 0.2892,
      "step": 6000
    },
    {
      "epoch": 5.697373071033102,
      "grad_norm": 5.391509532928467,
      "learning_rate": 2.1356985075344985e-06,
      "loss": 0.2806,
      "step": 6050
    },
    {
      "epoch": 5.744492873129933,
      "grad_norm": 5.3282318115234375,
      "learning_rate": 2.0556673501844114e-06,
      "loss": 0.2874,
      "step": 6100
    },
    {
      "epoch": 5.791612675226764,
      "grad_norm": 5.7925519943237305,
      "learning_rate": 1.97677470197489e-06,
      "loss": 0.2979,
      "step": 6150
    },
    {
      "epoch": 5.838732477323595,
      "grad_norm": 5.123918533325195,
      "learning_rate": 1.8990510689702213e-06,
      "loss": 0.2945,
      "step": 6200
    },
    {
      "epoch": 5.885852279420426,
      "grad_norm": 4.819815635681152,
      "learning_rate": 1.8225265052020475e-06,
      "loss": 0.2887,
      "step": 6250
    },
    {
      "epoch": 5.932972081517257,
      "grad_norm": 5.323462963104248,
      "learning_rate": 1.747230601048115e-06,
      "loss": 0.3036,
      "step": 6300
    },
    {
      "epoch": 5.980091883614088,
      "grad_norm": 5.812546730041504,
      "learning_rate": 1.673192471790332e-06,
      "loss": 0.2945,
      "step": 6350
    },
    {
      "epoch": 6.026387089174225,
      "grad_norm": 5.350496292114258,
      "learning_rate": 1.6004407463565187e-06,
      "loss": 0.2842,
      "step": 6400
    },
    {
      "epoch": 6.073506891271057,
      "grad_norm": 5.13112211227417,
      "learning_rate": 1.5290035562502286e-06,
      "loss": 0.2645,
      "step": 6450
    },
    {
      "epoch": 6.120626693367888,
      "grad_norm": 7.323594093322754,
      "learning_rate": 1.4589085246729062e-06,
      "loss": 0.267,
      "step": 6500
    },
    {
      "epoch": 6.167746495464719,
      "grad_norm": 5.300278186798096,
      "learning_rate": 1.3901827558426051e-06,
      "loss": 0.275,
      "step": 6550
    },
    {
      "epoch": 6.21486629756155,
      "grad_norm": 5.401418209075928,
      "learning_rate": 1.3228528245133738e-06,
      "loss": 0.2654,
      "step": 6600
    },
    {
      "epoch": 6.261986099658381,
      "grad_norm": 6.579848289489746,
      "learning_rate": 1.2569447656993789e-06,
      "loss": 0.2749,
      "step": 6650
    },
    {
      "epoch": 6.3091059017552125,
      "grad_norm": 5.551239490509033,
      "learning_rate": 1.1924840646077368e-06,
      "loss": 0.2596,
      "step": 6700
    },
    {
      "epoch": 6.3562257038520436,
      "grad_norm": 5.814754962921143,
      "learning_rate": 1.129495646783938e-06,
      "loss": 0.2675,
      "step": 6750
    },
    {
      "epoch": 6.403345505948875,
      "grad_norm": 5.201961040496826,
      "learning_rate": 1.06800386847368e-06,
      "loss": 0.2685,
      "step": 6800
    },
    {
      "epoch": 6.450465308045707,
      "grad_norm": 6.038691520690918,
      "learning_rate": 1.0080325072048458e-06,
      "loss": 0.273,
      "step": 6850
    },
    {
      "epoch": 6.497585110142538,
      "grad_norm": 5.347169399261475,
      "learning_rate": 9.496047525932506e-07,
      "loss": 0.2711,
      "step": 6900
    },
    {
      "epoch": 6.544704912239369,
      "grad_norm": 5.455114364624023,
      "learning_rate": 8.927431973757195e-07,
      "loss": 0.2741,
      "step": 6950
    },
    {
      "epoch": 6.5918247143362,
      "grad_norm": 5.0574469566345215,
      "learning_rate": 8.374698286739774e-07,
      "loss": 0.2813,
      "step": 7000
    },
    {
      "epoch": 6.638944516433031,
      "grad_norm": 5.573460578918457,
      "learning_rate": 7.838060194926977e-07,
      "loss": 0.2698,
      "step": 7050
    },
    {
      "epoch": 6.686064318529862,
      "grad_norm": 4.804764747619629,
      "learning_rate": 7.317725204550419e-07,
      "loss": 0.272,
      "step": 7100
    },
    {
      "epoch": 6.733184120626693,
      "grad_norm": 5.4277825355529785,
      "learning_rate": 6.813894517788361e-07,
      "loss": 0.2725,
      "step": 7150
    },
    {
      "epoch": 6.780303922723524,
      "grad_norm": 6.07441520690918,
      "learning_rate": 6.326762954965288e-07,
      "loss": 0.2663,
      "step": 7200
    },
    {
      "epoch": 6.827423724820356,
      "grad_norm": 6.230950355529785,
      "learning_rate": 5.85651887921907e-07,
      "loss": 0.2693,
      "step": 7250
    },
    {
      "epoch": 6.874543526917187,
      "grad_norm": 5.240156173706055,
      "learning_rate": 5.403344123665128e-07,
      "loss": 0.2733,
      "step": 7300
    },
    {
      "epoch": 6.921663329014018,
      "grad_norm": 5.1163506507873535,
      "learning_rate": 4.967413921085523e-07,
      "loss": 0.2727,
      "step": 7350
    },
    {
      "epoch": 6.9687831311108495,
      "grad_norm": 5.629495143890381,
      "learning_rate": 4.548896836170191e-07,
      "loss": 0.2698,
      "step": 7400
    },
    {
      "epoch": 7.015078336670986,
      "grad_norm": 4.963155746459961,
      "learning_rate": 4.147954700336765e-07,
      "loss": 0.2721,
      "step": 7450
    },
    {
      "epoch": 7.062198138767817,
      "grad_norm": 5.642316818237305,
      "learning_rate": 3.764742549153844e-07,
      "loss": 0.2557,
      "step": 7500
    },
    {
      "epoch": 7.109317940864648,
      "grad_norm": 5.240950107574463,
      "learning_rate": 3.3994085623921036e-07,
      "loss": 0.2552,
      "step": 7550
    },
    {
      "epoch": 7.156437742961479,
      "grad_norm": 5.330198764801025,
      "learning_rate": 3.0520940067264857e-07,
      "loss": 0.2668,
      "step": 7600
    },
    {
      "epoch": 7.2035575450583105,
      "grad_norm": 4.564249038696289,
      "learning_rate": 2.7229331811113647e-07,
      "loss": 0.2714,
      "step": 7650
    },
    {
      "epoch": 7.250677347155142,
      "grad_norm": 5.020258903503418,
      "learning_rate": 2.412053364850164e-07,
      "loss": 0.2658,
      "step": 7700
    },
    {
      "epoch": 7.2977971492519735,
      "grad_norm": 5.117839336395264,
      "learning_rate": 2.1195747683791734e-07,
      "loss": 0.2625,
      "step": 7750
    },
    {
      "epoch": 7.344916951348805,
      "grad_norm": 5.617311477661133,
      "learning_rate": 1.8456104867848212e-07,
      "loss": 0.2573,
      "step": 7800
    },
    {
      "epoch": 7.392036753445636,
      "grad_norm": 6.417629241943359,
      "learning_rate": 1.5902664560722704e-07,
      "loss": 0.2575,
      "step": 7850
    },
    {
      "epoch": 7.439156555542467,
      "grad_norm": 5.64792537689209,
      "learning_rate": 1.3536414122022777e-07,
      "loss": 0.2744,
      "step": 7900
    },
    {
      "epoch": 7.486276357639298,
      "grad_norm": 5.070469856262207,
      "learning_rate": 1.1358268529121363e-07,
      "loss": 0.2534,
      "step": 7950
    },
    {
      "epoch": 7.533396159736129,
      "grad_norm": 5.0709733963012695,
      "learning_rate": 9.369070023355353e-08,
      "loss": 0.2647,
      "step": 8000
    },
    {
      "epoch": 7.58051596183296,
      "grad_norm": 5.427687168121338,
      "learning_rate": 7.569587784348909e-08,
      "loss": 0.2677,
      "step": 8050
    },
    {
      "epoch": 7.627635763929791,
      "grad_norm": 6.413328647613525,
      "learning_rate": 5.960517632588813e-08,
      "loss": 0.2622,
      "step": 8100
    },
    {
      "epoch": 7.674755566026622,
      "grad_norm": 4.3207807540893555,
      "learning_rate": 4.542481760365647e-08,
      "loss": 0.2618,
      "step": 8150
    },
    {
      "epoch": 7.721875368123454,
      "grad_norm": 5.4788384437561035,
      "learning_rate": 3.3160284911855636e-08,
      "loss": 0.2649,
      "step": 8200
    },
    {
      "epoch": 7.768995170220285,
      "grad_norm": 5.37901496887207,
      "learning_rate": 2.281632067745898e-08,
      "loss": 0.2714,
      "step": 8250
    },
    {
      "epoch": 7.816114972317116,
      "grad_norm": 5.061436653137207,
      "learning_rate": 1.4396924685555758e-08,
      "loss": 0.26,
      "step": 8300
    },
    {
      "epoch": 7.8632347744139475,
      "grad_norm": 6.0095696449279785,
      "learning_rate": 7.905352532722177e-09,
      "loss": 0.2622,
      "step": 8350
    },
    {
      "epoch": 7.910354576510779,
      "grad_norm": 5.83053731918335,
      "learning_rate": 3.344114368153406e-09,
      "loss": 0.2623,
      "step": 8400
    },
    {
      "epoch": 7.95747437860761,
      "grad_norm": 5.481144428253174,
      "learning_rate": 7.149739230455366e-10,
      "loss": 0.2591,
      "step": 8450
    }
  ],
  "logging_steps": 50,
  "max_steps": 8488,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.760384613777408e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
